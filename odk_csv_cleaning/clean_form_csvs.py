#!/usr/local/bin/python
# -*- coding: utf-8 -*-

#This code is licensed under the 3-Clause BSD License.

#Copyright (c) 2018 Apple Inc. All rights reserved.

#Redistribution and use in source and binary forms, with or without modification, 
#are permitted provided that the following conditions are met:  

#1. Redistributions of source code must retain 
	#the above copyright notice, 
	#this list of conditions and the following disclaimer.

#2. Redistributions in binary form must reproduce the 
	#above copyright notice, 
    #this list of conditions and the following disclaimer 
    #in the documentation 
    #and/or other materials provided with the distribution.

#3. Neither the name of the copyright holder(s) 
	#nor the names of any 
    #contributors may be used to endorse 
    #or promote products derived from this 
    #software without specific prior written permission.

#THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND 
#ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED 
#WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.  
#IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, 
#INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES 
#(INCLUDING,  BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; 
#LOSS OF USE, DATA,  OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND 
#ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT 
#(INCLUDING NEGLIGENCE OR OTHERWISE)  ARISING IN ANY WAY OUT OF THE USE OF 
#THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

### Name: Clean Form CSVs
### Version: 0.8
### Dependencies: Pandas

## Import modules

try:
	import csv
	import argparse
	import os
	import io
	import pandas as pd
	from pandas.io.parsers import read_csv

## Install Pandas if it is not already installed

except ImportError:
	os.system('pip install pandas')

## Create arguments

parser = argparse.ArgumentParser(description='This script is meant to aid in the cleaning and merging of data from ODK csv forms. clean_field_csvs.py handles one argument at a time, with an option to add -n/--name for a custom output name of a given file.')

parser.add_argument("file", help="Provide a csv file, or path to directory of csv's for this argument")
parser.add_argument("-p", "--prepcsv", action="store_true", help="**DO THIS FIRST!** Prep raw_csvs from Kobo for processing.")
parser.add_argument("-n", "--name", action="store_true", help="Add a custom name for output file. This can be combined with most other arguments.")
parser.add_argument("-f", "--fixlatlon", action="store_true", help="Fix Lat/Lon Column Names")
parser.add_argument("-cw", "--cleanwhitespace", action="store_true", help="Clean leading/trailing whitespace")
parser.add_argument("-rc", "--removecolumn", action="store_true", help="Remove columns with ALL empty values")
parser.add_argument("-rf", "--removefield", action="store_true", help="Remove non-osm columns")
parser.add_argument("-rd", "--removeduplicates", action="store_true", help="Remove duplicate columns generated by multiple choice questions")
parser.add_argument("-oc", "--osmconform", action="store_true", help="Convert '_' in column headings to ':' as accepted by osm")
parser.add_argument("-brd", "--batchremoveduplicates", action="store_true", help="Remove duplicate columns generated by multiple choice questions. Provide full path for directories outside your working directory. Provide '.' if your files are in your current working directory.")
parser.add_argument("-boc", "--batchosmconform", action="store_true", help="Batch convert '_' in column headings to ':' as accepted by osm. Provide full path for directories outside your working directory. Provide '.' if your files are in your current working directory.")
parser.add_argument("-bcw", "--batchcleanwhitespace", action="store_true", help="Batch clean leading/trailing whitespace. Provide full path for directories outside your working directory. Provide '.' if your files are in your current working directory.")
parser.add_argument("-brc", "--batchremovecolumn", action="store_true", help="Batch remove columns with ALL empty values. Provide full path for directories outside your working directory. Provide '.' if your files are in your current working directory.")
parser.add_argument("-brf", "--batchremovefield", action="store_true", help="Batch remove non-osm columns. Provide full path for directories outside your working directory. Provide '.' if your files are in your current working directory.")
parser.add_argument("-bf", "--batchfixlatlon", action="store_true", help="Batch Fix Lat/Lon Column Names. Provide full path for directories outside your working directory. Provide '.' if your files are in your current working directory.")
parser.add_argument("-bm", "--batchmergecsv", action="store_true", help="Batch merge CSVs of same type. Provide full path for directories outside your working directory. Provide '.' if your files are in your current working directory.")

args = parser.parse_args()

## Prep all Kobo form data for processing

if args.file and args.prepcsv:
	if args.file.endswith('/'):
		filenames = os.listdir(args.file)
		for filename in filenames:
			if filename.endswith('.csv'):
				data = read_csv(args.file+filename, delimiter=";")
				data.to_csv(args.file+filename, quoting=csv.QUOTE_ALL, index=False)
		print '			'
		print 'CSV prep complete!'
		print '			'
	elif args.file == '.':
		path = os.getcwd()
		filenames = os.listdir(path)
		for filename in filenames:
			if filename.endswith('.csv'):
				data = read_csv(filename, delimiter=";")
				data.to_csv(filename, quoting=csv.QUOTE_ALL, index=False)
		print '			'
		print 'CSV prep complete!'
		print '			'
	elif args.file.endswith('.csv'):
			data = read_csv(args.file, delimiter=";")
			data.to_csv(args.file, quoting=csv.QUOTE_ALL, index=False)
			print '			'
			print 'CSV prep complete!'
			print '			'
	else:
		print '				'
		print 'Something went wrong...'
		print '				'


## Batch fix of field kobo server lat/lon information for QGIS compatibility

elif args.file and args.batchfixlatlon:
	if args.file.endswith('/'):
		filenames = os.listdir(args.file)
		for filename in filenames:
			if filename.endswith('.csv'):
				data = read_csv(args.file+filename)
				old_names = {
				'_cbi_facility_point_latitude' : 'latitude',
				'_cbi_facility_point_longitude' : 'longitude',
				'_education_facility_point_latitude' : 'latitude',
				'_education_facility_point_longitude' : 'longitude',
				'_health_facility_point_latitude' : 'latitude',
				'_health_facility_point_longitude' : 'longitude',
				'_other_facilities_point_latitude' : 'latitude',
				'_other_facilities_point_longitude' : 'longitude',
				'_community_name_latitude' : 'latitude',
				'_community_name_longitude' : 'longitude',
				'_community_geopoint_latitude' : 'latitude',
				'_community_geopoint_longitude' : 'longitude',
				'_wash_facility_point_latitude' : 'latitude',
				'_wash_facility_point_longitude' : 'longitude'
				}
				edited_data = data.rename(columns = old_names)
				edited_data.to_csv(args.file+filename, quoting=csv.QUOTE_ALL, index=False)
		print '				'
		print 'Batch fix of lat/lons complete!'
		print '				'
	
	elif args.file == '.':
		path = os.getcwd()
		filenames = os.listdir(path)
		for filename in filenames:
			if filename.endswith('.csv'):
				data = read_csv(filename)
				old_names = {
				'_cbi_facility_point_latitude' : 'latitude',
				'_cbi_facility_point_longitude' : 'longitude',
				'_education_facility_point_latitude' : 'latitude',
				'_education_facility_point_longitude' : 'longitude',
				'_health_facility_point_latitude' : 'latitude',
				'_health_facility_point_longitude' : 'longitude',
				'_other_facilities_point_latitude' : 'latitude',
				'_other_facilities_point_longitude' : 'longitude',
				'_community_name_latitude' : 'latitude',
				'_community_name_longitude' : 'longitude',
				'_community_geopoint_latitude' : 'latitude',
				'_community_geopoint_longitude' : 'longitude',
				'_wash_facility_point_latitude' : 'latitude',
				'_wash_facility_point_longitude' : 'longitude'
				}
				edited_data = data.rename(columns = old_names)
				edited_data.to_csv(filename, quoting=csv.QUOTE_ALL, index=False)
		print '				'
		print 'Batch fix of lat/lons complete!'
		print '				'
	else:
		print 'You have selected the wrong argument. Please try again.'

## Batch merging of CSV data - allows for a custom out file name

elif args.file and args.batchmergecsv and args.name:
	newName = raw_input("Enter File Name: ")
	if args.file.endswith('/'):
		filenames = os.listdir(args.file)
		fieldnames = []
		for filename in filenames:
			with open(args.file+'/'+filename, "r") as f_in:
				reader = csv.reader(f_in)
				headers = next(reader)
				for h in headers:
					if h not in fieldnames:
						fieldnames.append(h)
		with open(newName+".csv", "wb") as f_out:
			writer = csv.DictWriter(f_out, fieldnames=fieldnames)
			writer.writeheader()
			for filename in filenames:
				with open(args.file+'/'+filename, "r") as f_in:
					reader = csv.DictReader(f_in)
					for line in reader:
						writer.writerow(line)
		print '				'
		print 'Batch merge complete!'
		print '				'
	elif args.file == '.':
		path = os.getcwd()
		filenames = os.listdir(path)
		fieldnames = []
		for filename in filenames:
			if filename.endswith('.csv'):
				with open(filename, "r") as f_in:
					reader = csv.reader(f_in)
					headers = next(reader)
					for h in headers:
						if h not in fieldnames:
							fieldnames.append(h)
		with open(newName+".csv", "wb") as f_out:
			writer = csv.DictWriter(f_out, fieldnames=fieldnames)
			writer.writeheader()
			for filename in filenames:
				if filename.endswith('.csv'):
					with open(filename, "r") as f_in:
						reader = csv.DictReader(f_in)
						for line in reader:
							writer.writerow(line)
		print '				'
		print 'Batch merge complete!'
		print '				'
	else:
		print '					'
		print 'Something went wrong...'
		print '					'

## Batch merging of CSV data - without custom name

elif args.file and args.batchmergecsv:
	if args.file.endswith('/'):
		filenames = os.listdir(args.file)
		fieldnames = []
		for filename in filenames:
			with open(args.file+'/'+filename, "r") as f_in:
				reader = csv.reader(f_in)
				headers = next(reader)
				for h in headers:
					if h not in fieldnames:
						fieldnames.append(h)
		with open("merged_csv_output.csv", "wb") as f_out:
			writer = csv.DictWriter(f_out, fieldnames=fieldnames)
			writer.writeheader()
			for filename in filenames:
				with open(args.file+'/'+filename, "r") as f_in:
					reader = csv.DictReader(f_in)
					for line in reader:
						writer.writerow(line)
		print '				'
		print 'Batch merge complete!'
		print '				'
	elif args.file == '.':
		path = os.getcwd()
		filenames = os.listdir(path)
		fieldnames = []
		for filename in filenames:
			if filename.endswith('.csv'):
				with open(filename, "r") as f_in:
					reader = csv.reader(f_in)
					headers = next(reader)
					for h in headers:
						if h not in fieldnames:
							fieldnames.append(h)
		with open("merged_csv_output.csv", "wb") as f_out:
			writer = csv.DictWriter(f_out, fieldnames=fieldnames)
			writer.writeheader()
			for filename in filenames:
				if filename.endswith('.csv'):
					with open(filename, "r") as f_in:
						reader = csv.DictReader(f_in)
						for line in reader:
							writer.writerow(line)
		print '				'
		print 'Batch merge complete!'
		print '				'
	else:
		print '					'
		print 'Something went wrong...'
		print '					'

## Batch reformat _ to : for osm
elif args.file and args.batchosmconform:
	if args.file.endswith('/'):
		filenames = os.listdir(args.file)
		for filename in filenames:
			if filename.endswith('.csv'):
				data = read_csv(args.file+filename)
				old_names = {
				'addr_district' : 'addr:district',
				'addr_county' : 'addr:county',
				'addr_subcounty' : 'addr:subcounty',
				'addr_parish' : 'addr:parish',
				'addr_lc_village' : 'addr:lc_village',
				'addr_rs_village' : 'addr:rs_village',
				'addr_settlement' : 'addr:settlement',
				'addr_zone' : 'addr:zone',
				'addr_block' : 'addr:block'
				}
				edited_data = data.rename(columns = old_names)
				edited_data.to_csv(args.file+filename, quoting=csv.QUOTE_ALL, index=False)
		print '				'
		print 'Batch fix of Address columns to OSM Standards!'
		print '				'
	
	elif args.file == '.':
		path = os.getcwd()
		filenames = os.listdir(path)
		for filename in filenames:
			if filename.endswith('.csv'):
				data = read_csv(filename)
				old_names = {
				'addr_district' : 'addr:district',
				'addr_county' : 'addr:county',
				'addr_subcounty' : 'addr:subcounty',
				'addr_parish' : 'addr:parish',
				'addr_lc_village' : 'addr:lc_village',
				'addr_rs_village' : 'addr:rs_village',
				'addr_settlement' : 'addr:settlement',
				'addr_zone' : 'addr:zone',
				'addr_block' : 'addr:block'
				}
				edited_data = data.rename(columns = old_names)
				edited_data.to_csv(filename, quoting=csv.QUOTE_ALL, index=False)
		print '				'
		print 'Batch fix of Address columns to OSM Standards!'
		print '				'
	else:
		print 'You have selected the wrong argument. Please try again.'

## Single file reformat of _ to : for osm with custom name

elif args.file and args.osmconform and args.name:
	if args.file.startswith("'/"):
		filenames = args.file
		newName = raw_input("Enter File Name: ")
		for filename in filenames:
			data = read_csv(args.file+filename)
			old_names = {
			'addr_district' : 'addr:district',
			'addr_county' : 'addr:county',
			'addr_subcounty' : 'addr:subcounty',
			'addr_parish' : 'addr:parish',
			'addr_lc_village' : 'addr:lc_village',
			'addr_rs_village' : 'addr:rs_village',
			'addr_settlement' : 'addr:settlement',
			'addr_zone' : 'addr:zone',
			'addr_block' : 'addr:block'
			}
			edited_data = data.rename(columns = old_names)
			edited_data.to_csv(newName+'.csv', quoting=csv.QUOTE_ALL, index=False)
		print '				'
		print 'Address columns now conform to OSM Standards!'
		print '				'
	elif args.file.endswith('/'):
		filenames = args.file
		newName = raw_input("Enter File Name: ")
		for filename in filenames:
			data = read_csv(args.file+filename)
			old_names = {
			'addr_district' : 'addr:district',
			'addr_county' : 'addr:county',
			'addr_subcounty' : 'addr:subcounty',
			'addr_parish' : 'addr:parish',
			'addr_lc_village' : 'addr:lc_village',
			'addr_rs_village' : 'addr:rs_village',
			'addr_settlement' : 'addr:settlement',
			'addr_zone' : 'addr:zone',
			'addr_block' : 'addr:block'
			}
			edited_data = data.rename(columns = old_names)
			edited_data.to_csv(newName+'.csv', quoting=csv.QUOTE_ALL, index=False)
		print '				'
		print 'Address columns now conform to OSM Standards!'
		print '				'
	else:
		filenames = args.file
		newName = raw_input("Enter File Name: ")
		for filename in filenames:
			data = read_csv(args.file)
			old_names = {
			'addr_district' : 'addr:district',
			'addr_county' : 'addr:county',
			'addr_subcounty' : 'addr:subcounty',
			'addr_parish' : 'addr:parish',
			'addr_lc_village' : 'addr:lc_village',
			'addr_rs_village' : 'addr:rs_village',
			'addr_settlement' : 'addr:settlement',
			'addr_zone' : 'addr:zone',
			'addr_block' : 'addr:block'
			}
			edited_data = data.rename(columns = old_names)
			edited_data.to_csv(newName+'.csv', quoting=csv.QUOTE_ALL, index=False)
		print '				'
		print 'Address columns now conform to OSM Standards!'
		print '				'

## Single file reformat of _ to : for osm

elif args.file and args.osmconform:
	if args.file.startswith("'/"):
		filenames = args.file
		for filename in filenames:
			data = read_csv(args.file+filename)
			old_names = {
			'addr_district' : 'addr:district',
			'addr_county' : 'addr:county',
			'addr_subcounty' : 'addr:subcounty',
			'addr_parish' : 'addr:parish',
			'addr_lc_village' : 'addr:lc_village',
			'addr_rs_village' : 'addr:rs_village',
			'addr_settlement' : 'addr:settlement',
			'addr_zone' : 'addr:zone',
			'addr_block' : 'addr:block'
			}
			edited_data = data.rename(columns = old_names)
			edited_data.to_csv(filename, quoting=csv.QUOTE_ALL, index=False)
		print '				'
		print 'Address columns now conform to OSM Standards!'
		print '				'
	elif args.file.endswith('/'):
		filenames = args.file
		for filename in filenames:
			data = read_csv(args.file+filename)
			old_names = {
			'addr_district' : 'addr:district',
			'addr_county' : 'addr:county',
			'addr_subcounty' : 'addr:subcounty',
			'addr_parish' : 'addr:parish',
			'addr_lc_village' : 'addr:lc_village',
			'addr_rs_village' : 'addr:rs_village',
			'addr_settlement' : 'addr:settlement',
			'addr_zone' : 'addr:zone',
			'addr_block' : 'addr:block'
			}
			edited_data = data.rename(columns = old_names)
			edited_data.to_csv(filename, quoting=csv.QUOTE_ALL, index=False)
		print '				'
		print 'Address columns now conform to OSM Standards!'
		print '				'
	else:
		filenames = args.file
		for filename in filenames:
			data = read_csv(args.file)
			old_names = {
			'addr_district' : 'addr:district',
			'addr_county' : 'addr:county',
			'addr_subcounty' : 'addr:subcounty',
			'addr_parish' : 'addr:parish',
			'addr_lc_village' : 'addr:lc_village',
			'addr_rs_village' : 'addr:rs_village',
			'addr_settlement' : 'addr:settlement',
			'addr_zone' : 'addr:zone',
			'addr_block' : 'addr:block'
			}
			edited_data = data.rename(columns = old_names)
			edited_data.to_csv(args.file, quoting=csv.QUOTE_ALL, index=False)
		print '				'
		print 'Address columns now conform to OSM Standards!'
		print '				'


## Single file fix of field kobo server lat/lon information for QGIS compatibility - allows for a custom out file name

elif args.file and args.fixlatlon and args.name:
	filenames = args.file
	newName = raw_input("Enter File Name: ")
	for filename in filenames:
		data = read_csv(args.file)
		old_names = {
		'_cbi_facility_point_latitude' : 'latitude',
		'_cbi_facility_point_longitude' : 'longitude',
		'_education_facility_point_latitude' : 'latitude',
		'_education_facility_point_longitude' : 'longitude',
		'_health_facility_point_latitude' : 'latitude',
		'_health_facility_point_longitude' : 'longitude',
		'_other_facilities_point_latitude' : 'latitude',
		'_other_facilities_point_longitude' : 'longitude',
		'_community_name_latitude' : 'latitude',
		'_community_name_longitude' : 'longitude',
		'_community_geopoint_latitude' : 'latitude',
		'_community_geopoint_longitude' : 'longitude',
		'_wash_facility_point_latitude' : 'latitude',
		'_wash_facility_point_longitude' : 'longitude'
		}
		edited_data = data.rename(columns = old_names)
		edited_data.to_csv(newName+'.csv', quoting=csv.QUOTE_ALL, index=False)
	print '				'
	print 'Fix of lat/lon complete!'
	print '				'

## Single file fix of field kobo server lat/lon information for QGIS compatibility

elif args.file and args.fixlatlon:
	if args.file.startswith("'/"):
		filenames = args.file
		for filename in filenames:
			data = read_csv(args.file+filename)
			old_names = {
			'_cbi_facility_point_latitude' : 'latitude',
			'_cbi_facility_point_longitude' : 'longitude',
			'_education_facility_point_latitude' : 'latitude',
			'_education_facility_point_longitude' : 'longitude',
			'_health_facility_point_latitude' : 'latitude',
			'_health_facility_point_longitude' : 'longitude',
			'_other_facilities_point_latitude' : 'latitude',
			'_other_facilities_point_longitude' : 'longitude',
			'_community_name_latitude' : 'latitude',
			'_community_name_longitude' : 'longitude',
			'_community_geopoint_latitude' : 'latitude',
			'_community_geopoint_longitude' : 'longitude',
			'_wash_facility_point_latitude' : 'latitude',
			'_wash_facility_point_longitude' : 'longitude'
			}
			edited_data = data.rename(columns = old_names)
			edited_data.to_csv(filename+'_editedlatlon.csv', quoting=csv.QUOTE_ALL, index=False)
		print '				'
		print 'Fix of lat/lon complete!'
		print '				'
	else:
		filenames = args.file
		for filename in filenames:
			data = read_csv(args.file)
			old_names = {
			'_cbi_facility_point_latitude' : 'latitude',
			'_cbi_facility_point_longitude' : 'longitude',
			'_education_facility_point_latitude' : 'latitude',
			'_education_facility_point_longitude' : 'longitude',
			'_health_facility_point_latitude' : 'latitude',
			'_health_facility_point_longitude' : 'longitude',
			'_other_facilities_point_latitude' : 'latitude',
			'_other_facilities_point_longitude' : 'longitude',
			'_community_name_latitude' : 'latitude',
			'_community_name_longitude' : 'longitude',
			'_community_geopoint_latitude' : 'latitude',
			'_community_geopoint_longitude' : 'longitude',
			'_wash_facility_point_latitude' : 'latitude',
			'_wash_facility_point_longitude' : 'longitude'
			}
			edited_data = data.rename(columns = old_names)
			edited_data.to_csv(args.file, quoting=csv.QUOTE_ALL, index=False)
		print '				'
		print 'Fix of lat/lon complete!'
		print '				'

## Batch remove duplicate columns

elif args.file and args.batchremoveduplicates:
	if args.file.endswith('/'):
		filenames = os.listdir(args.file)
		for filename in filenames:
			if filename.endswith('.csv'):
				data = read_csv(args.file+filename)
				edited_data = data.drop(list(data.filter(regex = '/')), axis = 1)
				edited_data.to_csv(args.file+filename, quoting=csv.QUOTE_ALL, index=False)
		print '				'
		print 'Batch removal of duplicate/unnecessary columns complete!'
		print '				'
	
	elif args.file == '.':
		path = os.getcwd()
		filenames = os.listdir(path)
		for filename in filenames:
			if filename.endswith('.csv'):
				data = read_csv(filename)
				edited_data = data.drop(list(data.filter(regex = '/')), axis = 1)
				edited_data.to_csv(filename, quoting=csv.QUOTE_ALL, index=False)
		print '				'
		print 'Batch removal of duplicate/unnecessary columns complete!'
		print '				'
	else:
		print 'You have selected the wrong argument. Please try again.'

## Single file duplicate columns removal - allows for a custom out file name
        	
elif args.file and args.removeduplicates and args.name:
	data = read_csv(args.file)
	fileName = raw_input("Enter File Name: ")
	filtered_data = data.drop(list(data.filter(regex = '/')), axis = 1)
	filtered_data.to_csv(fileName+'.csv', quoting=csv.QUOTE_ALL, index=False)
	print '				'
	print 'Removed duplicate/unnecessary columns!'
	print '				'

## Single file duplicate columns removal
        	
elif args.file and args.removeduplicates:
	data = read_csv(args.file)
	filtered_data = data.drop(list(data.filter(regex = '/')), axis = 1)
	filtered_data.to_csv(args.file, quoting=csv.QUOTE_ALL, index=False)
	print '				'
	print 'Removed duplicate/unnecessary columns!'
	print '				'

## Batch remove empty columns

elif args.file and args.batchremovecolumn:
	if args.file.endswith('/'):
		filenames = os.listdir(args.file)
		for filename in filenames:
			if filename.endswith('.csv'):
				data = read_csv(args.file+filename)
				edited_data = data.dropna(axis='columns', how='all')
				edited_data.to_csv(args.file+filename, quoting=csv.QUOTE_ALL, index=False)
		print '				'
		print 'Batch removal of empty columns complete!'
		print '				'
	
	elif args.file == '.':
		path = os.getcwd()
		filenames = os.listdir(path)
		for filename in filenames:
			if filename.endswith('.csv'):
				data = read_csv(filename)
				edited_data = data.dropna(axis='columns', how='all')
				edited_data.to_csv(filename, quoting=csv.QUOTE_ALL, index=False)
		print '				'
		print 'Batch removal of empty columns complete!'
		print '				'
	else:
		print 'You have selected the wrong argument. Please try again.'


## Single file empty columns removal - allows for a custom out file name
        	
elif args.file and args.removecolumn and args.name:
	data = read_csv(args.file)
	fileName = raw_input("Enter File Name: ")
	filtered_data = data.dropna(axis='columns', how='all')
	filtered_data.to_csv(fileName+'.csv', quoting=csv.QUOTE_ALL, index=False)
	print '				'
	print 'Removed blank columns!'
	print '				'

## Single file empty column removal

elif args.file and args.removecolumn:
	data = read_csv(args.file)
	filtered_data = data.dropna(axis='columns', how='all')
	filtered_data.to_csv(args.file, quoting=csv.QUOTE_ALL, index=False)
	print '				'
	print 'Removed blank columns!'
	print '				'


## Batch remove non-osm fields

elif args.file and args.batchremovefield:
	if args.file.endswith('/'):
		filenames = os.listdir(args.file)
		for filename in filenames:
			if filename.endswith('.csv'):
				data = read_csv(args.file+filename)
				data.drop('start', axis=1, inplace=True, errors='ignore')
				data.drop('end', axis=1, inplace=True, errors='ignore')
				data.drop('today', axis=1, inplace=True, errors='ignore')
				data.drop('deviceid', axis=1, inplace=True, errors='ignore')
				data.drop('subscriberid', axis=1, inplace=True, errors='ignore')
				data.drop('simserial', axis=1, inplace=True, errors='ignore')
				data.drop('wash_facility_point', axis=1, inplace=True, errors='ignore')
				data.drop('_wash_facility_point_altitude', axis=1, inplace=True, errors='ignore')
				data.drop('_wash_facility_point_precision', axis=1, inplace=True, errors='ignore')
				data.drop('other_facility_point', axis=1, inplace=True, errors='ignore')
				data.drop('_other_facility_point_altitude', axis=1, inplace=True, errors='ignore')
				data.drop('_other_facility_point_precision', axis=1, inplace=True, errors='ignore')
				data.drop('cbi_facility_point', axis=1, inplace=True, errors='ignore')
				data.drop('_cbi_facility_point_altitude', axis=1, inplace=True, errors='ignore')
				data.drop('_cbi_facility_point_precision', axis=1, inplace=True, errors='ignore')
				data.drop('health_facility_point', axis=1, inplace=True, errors='ignore')
				data.drop('_health_facility_point_altitude', axis=1, inplace=True, errors='ignore')
				data.drop('_health_facility_point_precision', axis=1, inplace=True, errors='ignore')
				data.drop('education_facility_point', axis=1, inplace=True, errors='ignore')
				data.drop('_education_facility_point_altitude', axis=1, inplace=True, errors='ignore')
				data.drop('_education_facility_point_precision', axis=1, inplace=True, errors='ignore')
				data.drop('community_geopoint', axis=1, inplace=True, errors='ignore')
				data.drop('_community_geopoint_altitude', axis=1, inplace=True, errors='ignore')
				data.drop('_community_geopoint_precision', axis=1, inplace=True, errors='ignore')
				data.drop('status_representative', axis=1, inplace=True, errors='ignore')
				data.drop('name_representative', axis=1, inplace=True, errors='ignore')
				data.drop('contact_phone_number', axis=1, inplace=True, errors='ignore')
				data.drop('status_representative_other', axis=1, inplace=True, errors='ignore')
				data.drop('surveyor_comments', axis=1, inplace=True, errors='ignore')
				data.drop('phonenumber', axis=1, inplace=True, errors='ignore')
				data.drop('Humanitarian_OpenStreetMap_Survey', axis=1, inplace=True, errors='ignore')
				data.drop('thanks', axis=1, inplace=True, errors='ignore')
				data.drop('__version__', axis=1, inplace=True, errors='ignore')
				data.drop('_id', axis=1, inplace=True, errors='ignore')
				data.drop('_uuid', axis=1, inplace=True, errors='ignore')
				data.drop('_submission_time', axis=1, inplace=True, errors='ignore')
				data.drop('_index', axis=1, inplace=True, errors='ignore')
				data.to_csv(args.file+filename, quoting=csv.QUOTE_ALL, index=False)
		print '				'
		print 'Batch removal of non-osm fields complete!'
		print '				'
	
	elif args.file == '.':
		path = os.getcwd()
		filenames = os.listdir(path)
		for filename in filenames:
			if filename.endswith('.csv'):
				data = read_csv(filename)
				data.drop('start', axis=1, inplace=True, errors='ignore')
				data.drop('end', axis=1, inplace=True, errors='ignore')
				data.drop('today', axis=1, inplace=True, errors='ignore')
				data.drop('deviceid', axis=1, inplace=True, errors='ignore')
				data.drop('subscriberid', axis=1, inplace=True, errors='ignore')
				data.drop('simserial', axis=1, inplace=True, errors='ignore')
				data.drop('wash_facility_point', axis=1, inplace=True, errors='ignore')
				data.drop('_wash_facility_point_altitude', axis=1, inplace=True, errors='ignore')
				data.drop('_wash_facility_point_precision', axis=1, inplace=True, errors='ignore')
				data.drop('other_facility_point', axis=1, inplace=True, errors='ignore')
				data.drop('_other_facility_point_altitude', axis=1, inplace=True, errors='ignore')
				data.drop('_other_facility_point_precision', axis=1, inplace=True, errors='ignore')
				data.drop('cbi_facility_point', axis=1, inplace=True, errors='ignore')
				data.drop('_cbi_facility_point_altitude', axis=1, inplace=True, errors='ignore')
				data.drop('_cbi_facility_point_precision', axis=1, inplace=True, errors='ignore')
				data.drop('health_facility_point', axis=1, inplace=True, errors='ignore')
				data.drop('_health_facility_point_altitude', axis=1, inplace=True, errors='ignore')
				data.drop('_health_facility_point_precision', axis=1, inplace=True, errors='ignore')
				data.drop('education_facility_point', axis=1, inplace=True, errors='ignore')
				data.drop('_education_facility_point_altitude', axis=1, inplace=True, errors='ignore')
				data.drop('_education_facility_point_precision', axis=1, inplace=True, errors='ignore')
				data.drop('community_geopoint', axis=1, inplace=True, errors='ignore')
				data.drop('_community_geopoint_altitude', axis=1, inplace=True, errors='ignore')
				data.drop('_community_geopoint_precision', axis=1, inplace=True, errors='ignore')
				data.drop('status_representative', axis=1, inplace=True, errors='ignore')
				data.drop('name_representative', axis=1, inplace=True, errors='ignore')
				data.drop('contact_phone_number', axis=1, inplace=True, errors='ignore')
				data.drop('status_representative_other', axis=1, inplace=True, errors='ignore')
				data.drop('surveyor_comments', axis=1, inplace=True, errors='ignore')
				data.drop('phonenumber', axis=1, inplace=True, errors='ignore')
				data.drop('Humanitarian_OpenStreetMap_Survey', axis=1, inplace=True, errors='ignore')
				data.drop('thanks', axis=1, inplace=True, errors='ignore')
				data.drop('__version__', axis=1, inplace=True, errors='ignore')
				data.drop('_id', axis=1, inplace=True, errors='ignore')
				data.drop('_uuid', axis=1, inplace=True, errors='ignore')
				data.drop('_submission_time', axis=1, inplace=True, errors='ignore')
				data.drop('_index', axis=1, inplace=True, errors='ignore')
				data.to_csv(filename, quoting=csv.QUOTE_ALL, index=False)
		print '				'
		print 'Batch removal of non-osm fields complete!'
		print '				'
	else:
		print 'You have selected the wrong argument. Please try again.'


## Single file osm cleaning columns removal - allows for a custom out file name
        	
elif args.file and args.removefield and args.name:
	data = read_csv(args.file)
	fileName = raw_input("Enter File Name: ")
	data.drop('start', axis=1, inplace=True, errors='ignore')
	data.drop('end', axis=1, inplace=True, errors='ignore')
	data.drop('today', axis=1, inplace=True, errors='ignore')
	data.drop('deviceid', axis=1, inplace=True, errors='ignore')
	data.drop('subscriberid', axis=1, inplace=True, errors='ignore')
	data.drop('simserial', axis=1, inplace=True, errors='ignore')
	data.drop('wash_facility_point', axis=1, inplace=True, errors='ignore')
	data.drop('_wash_facility_point_altitude', axis=1, inplace=True, errors='ignore')
	data.drop('_wash_facility_point_precision', axis=1, inplace=True, errors='ignore')
	data.drop('other_facility_point', axis=1, inplace=True, errors='ignore')
	data.drop('_other_facility_point_altitude', axis=1, inplace=True, errors='ignore')
	data.drop('_other_facility_point_precision', axis=1, inplace=True, errors='ignore')
	data.drop('cbi_facility_point', axis=1, inplace=True, errors='ignore')
	data.drop('_cbi_facility_point_altitude', axis=1, inplace=True, errors='ignore')
	data.drop('_cbi_facility_point_precision', axis=1, inplace=True, errors='ignore')
	data.drop('health_facility_point', axis=1, inplace=True, errors='ignore')
	data.drop('_health_facility_point_altitude', axis=1, inplace=True, errors='ignore')
	data.drop('_health_facility_point_precision', axis=1, inplace=True, errors='ignore')
	data.drop('education_facility_point', axis=1, inplace=True, errors='ignore')
	data.drop('_education_facility_point_altitude', axis=1, inplace=True, errors='ignore')
	data.drop('_education_facility_point_precision', axis=1, inplace=True, errors='ignore')
	data.drop('community_geopoint', axis=1, inplace=True, errors='ignore')
	data.drop('_community_geopoint_altitude', axis=1, inplace=True, errors='ignore')
	data.drop('_community_geopoint_precision', axis=1, inplace=True, errors='ignore')
	data.drop('status_representative', axis=1, inplace=True, errors='ignore')
	data.drop('name_representative', axis=1, inplace=True, errors='ignore')
	data.drop('contact_phone_number', axis=1, inplace=True, errors='ignore')
	data.drop('status_representative_other', axis=1, inplace=True, errors='ignore')
	data.drop('surveyor_comments', axis=1, inplace=True, errors='ignore')
	data.drop('phonenumber', axis=1, inplace=True, errors='ignore')
	data.drop('Humanitarian_OpenStreetMap_Survey', axis=1, inplace=True, errors='ignore')
	data.drop('thanks', axis=1, inplace=True, errors='ignore')
	data.drop('__version__', axis=1, inplace=True, errors='ignore')
	data.drop('_id', axis=1, inplace=True, errors='ignore')
	data.drop('_uuid', axis=1, inplace=True, errors='ignore')
	data.drop('_submission_time', axis=1, inplace=True, errors='ignore')
	data.drop('_index', axis=1, inplace=True, errors='ignore')
	data.to_csv(fileName+'.csv', quoting=csv.QUOTE_ALL, index=False)
	print '				'
	print 'Removed non-osm fields!'
	print '				'

## Single file osm cleaning column removal

elif args.file and args.removefield:
	data = read_csv(args.file)
	data.drop('start', axis=1, inplace=True, errors='ignore')
	data.drop('end', axis=1, inplace=True, errors='ignore')
	data.drop('today', axis=1, inplace=True, errors='ignore')
	data.drop('deviceid', axis=1, inplace=True, errors='ignore')
	data.drop('subscriberid', axis=1, inplace=True, errors='ignore')
	data.drop('simserial', axis=1, inplace=True, errors='ignore')
	data.drop('wash_facility_point', axis=1, inplace=True, errors='ignore')
	data.drop('_wash_facility_point_altitude', axis=1, inplace=True, errors='ignore')
	data.drop('_wash_facility_point_precision', axis=1, inplace=True, errors='ignore')
	data.drop('other_facility_point', axis=1, inplace=True, errors='ignore')
	data.drop('_other_facility_point_altitude', axis=1, inplace=True, errors='ignore')
	data.drop('_other_facility_point_precision', axis=1, inplace=True, errors='ignore')
	data.drop('cbi_facility_point', axis=1, inplace=True, errors='ignore')
	data.drop('_cbi_facility_point_altitude', axis=1, inplace=True, errors='ignore')
	data.drop('_cbi_facility_point_precision', axis=1, inplace=True, errors='ignore')
	data.drop('health_facility_point', axis=1, inplace=True, errors='ignore')
	data.drop('_health_facility_point_altitude', axis=1, inplace=True, errors='ignore')
	data.drop('_health_facility_point_precision', axis=1, inplace=True, errors='ignore')
	data.drop('education_facility_point', axis=1, inplace=True, errors='ignore')
	data.drop('_education_facility_point_altitude', axis=1, inplace=True, errors='ignore')
	data.drop('_education_facility_point_precision', axis=1, inplace=True, errors='ignore')
	data.drop('community_geopoint', axis=1, inplace=True, errors='ignore')
	data.drop('_community_geopoint_altitude', axis=1, inplace=True, errors='ignore')
	data.drop('_community_geopoint_precision', axis=1, inplace=True, errors='ignore')
	data.drop('status_representative', axis=1, inplace=True, errors='ignore')
	data.drop('name_representative', axis=1, inplace=True, errors='ignore')
	data.drop('contact_phone_number', axis=1, inplace=True, errors='ignore')
	data.drop('status_representative_other', axis=1, inplace=True, errors='ignore')
	data.drop('surveyor_comments', axis=1, inplace=True, errors='ignore')
	data.drop('phonenumber', axis=1, inplace=True, errors='ignore')
	data.drop('Humanitarian_OpenStreetMap_Survey', axis=1, inplace=True, errors='ignore')
	data.drop('thanks', axis=1, inplace=True, errors='ignore')
	data.drop('__version__', axis=1, inplace=True, errors='ignore')
	data.drop('_id', axis=1, inplace=True, errors='ignore')
	data.drop('_uuid', axis=1, inplace=True, errors='ignore')
	data.drop('_submission_time', axis=1, inplace=True, errors='ignore')
	data.drop('_index', axis=1, inplace=True, errors='ignore')
	data.to_csv(args.file, quoting=csv.QUOTE_ALL, index=False)
	print '				'
	print 'Removed non-osm fields!'
	print '				'


## Batch clean of leading/trailing whitespace

elif args.file and args.batchcleanwhitespace:
	if args.file.endswith('/'):
		filenames = os.listdir(args.file)
		for filename in filenames:
			if filename.endswith('.csv'):
				with open(args.file+filename.encode('utf-8')) as infile:
					reader = csv.DictReader(infile)
					next(reader, None)
					fieldnames = reader.fieldnames
					for row in reader:
						row.update({fieldname: str(value).strip() for (fieldname, value) in row.items()})
		print '				'
		print 'Batch cleaning of leading and trailing whitespace complete!'
		print '				'
	
	elif args.file == '.':
		path = os.getcwd()
		filenames = os.listdir(path)
		for filename in filenames:
			if filename.endswith('.csv'):
				with open(filename.encode('utf-8')) as infile:
					reader = csv.DictReader(infile)
					next(reader, None)
					fieldnames = reader.fieldnames
					for row in reader:
						row.update({fieldname: str(value).strip() for (fieldname, value) in row.items()})
		print '				'
		print 'Batch cleaning of leading and trailing whitespace complete!'
		print '				'
	else:
		print 'You have selected the wrong argument. Please try again.'


## Single file fix of leading/trailing whitespace

elif args.file and args.cleanwhitespace and args.name:
	fileName = raw_input("Enter File Name: ")
	with open(args.file.encode('utf-8')) as inFile, open(fileName+'.csv', 'wb') as outFile:
		r = csv.reader(inFile)
		w = csv.writer(outFile)
		next(reader, None)
		fieldnames = reader.fieldnames
		for row in reader:
			w.update({fieldname: str(value).strip() for (fieldname, value) in row.items()})
	print '				'
	print 'Cleaned leading and trailing whitespace!'
	print '				'

## Single file fix of leading/trailing whitespace

elif args.file and args.cleanwhitespace:
	with open(args.file.encode('utf-8')) as infile:
		reader = csv.DictReader(infile)
		next(reader, None)
		fieldnames = reader.fieldnames
		for row in reader:
			row.update({fieldname: str(value).strip() for (fieldname, value) in row.items()})
	print '				'
	print 'Cleaned leading and trailing whitespace!'
	print '				'

## If a file/directory is provided without any other arguments

elif args.file:
	print '						  '
	print 'Please provide a valid argument. More than a file/directory.'
	print '						  '

## If funky stuff happens

else:
	print '						  '
	print 'Something went wrong...'
	print '						  '
	print 'Please make sure you provide a csv/directoryOfCsvs as your input, and you have selected a proper argument.'